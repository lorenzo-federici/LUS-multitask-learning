{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb Cella 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# import custom lib\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperiment\u001b[39;00m \u001b[39mimport\u001b[39;00m Experiment\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m gpu \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/notebooks/experiment-launch.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m gpu:\n",
      "File \u001b[0;32m~/Univpm/Tesi/LUS-multitask-learning/src/experiment.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclass_weight\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_class_weight\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, SGD\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloss\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "base_path = '/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning'\n",
    "if base_path not in sys.path:\n",
    "    sys.path.append(base_path)\n",
    "\n",
    "# import custom lib\n",
    "from src.utils.dataset import *\n",
    "from bck.experiment import Experiment\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "if gpu:\n",
    "    tf.config.set_visible_devices([tf.config.list_physical_devices('GPU')[0],tf.config.list_physical_devices('CPU')[0]])\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "    print(\"---> GPU is available <---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_path = '/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/config/params.json'\n",
    "idx = 2\n",
    "\n",
    "with open(exps_path) as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "configs_general = configs['SETTING']\n",
    "base_path       = configs_general['BASE_PATH']\n",
    "configs_exps    = configs['EXPS'][idx]\n",
    "\n",
    "print('>>Setting: ', configs_general)\n",
    "print('>>Experiment: ', configs_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session\n",
    "for config in configs_exps:\n",
    "    experiment = Experiment(configs_general, config, output_mode= (1,0))\n",
    "\n",
    "experiment.build_experiment()\n",
    "experiment.split_dataset()\n",
    "# model = experiment.build_model()\n",
    "# model = experiment.compile_model(model)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.generate_split_charts('ldistr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_centersdict_path = os.path.join(\n",
    "    experiment.base_path, 'data/iclus', 'hospitals-patients-dict.pkl'\n",
    ")\n",
    "medical_center_patients, data_index, data_map_idxs_pcm, score_counts, labels = load_dsdata_pickle(experiment.dataset, pkl_centersdict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dizionario_originale = data_map_idxs_pcm\n",
    "score = labels\n",
    "\n",
    "nuovo_dizionario = {}\n",
    "\n",
    "for chiave, lista_indici in dizionario_originale.items():\n",
    "    lista_score = [score[i] for i in lista_indici]\n",
    "    mean_score = int(np.mean(lista_score))\n",
    "    nuovi_valori = [lista_indici, lista_score, mean_score]\n",
    "\n",
    "    nuovo_dizionario[chiave] = nuovi_valori\n",
    "\n",
    "print(nuovo_dizionario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indici = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "classi = [0, 1, 2, 3, 2, 1, 0, 3, 2, 1, 0, 3, 2, 1, 0, 3]\n",
    "print(\"Dimensione di indici:\", len(indici))\n",
    "print(\"Dimensione di classi:\", len(classi))\n",
    "\n",
    "\n",
    "# Creazione del dizionario\n",
    "class_movies = {}\n",
    "\n",
    "# Iterazione sugli elementi degli array\n",
    "for indice, classe in zip(indici, classi):\n",
    "    # Verifica se la classe è già una chiave nel class_movies\n",
    "    if classe in class_movies:\n",
    "        # Se sì, aggiungi l'indice alla lista esistente\n",
    "        class_movies[classe].append(indice)\n",
    "    else:\n",
    "        # Se no, crea una nuova chiave e associa l'indice come primo elemento della lista\n",
    "        class_movies[classe] = [indice]\n",
    "\n",
    "# Stampare il risultato\n",
    "print(class_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def select_movie(rnd_cls, class_dict):\n",
    "    \"\"\"\n",
    "    :param rnd_cls: one of the classes a pixel can be assigned to\n",
    "    For a given class rnd_cls, determines the probability of sampling a certain movie based on the amount of available frames and returns a movie_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the amount of frames per movie in this class\n",
    "    nr_frames_per_movie = []\n",
    "    [nr_frames_per_movie.append(len(class_dict[rnd_cls][i])) for i in class_dict[rnd_cls]]\n",
    "\n",
    "    # Bound the amount of frames on 50, to not explode probabilities for long movies\n",
    "    nr_frames_per_movie = np.array(nr_frames_per_movie)\n",
    "    nr_frames_per_movie_bounded = copy.deepcopy(nr_frames_per_movie)\n",
    "    nr_frames_per_movie_bounded[nr_frames_per_movie>50] = 50\n",
    "\n",
    "    # Compute the probabilities\n",
    "    probs = 0.2*(nr_frames_per_movie_bounded-1)+1\n",
    "\n",
    "    # Return the sampled movie, sampled using the defined probability distribution\n",
    "    movie_index = np.argmax(np.random.multinomial(1, probs/np.sum(probs)),-1)\n",
    "    return movie_index\n",
    "\n",
    "def class_balanced_batch_generator(classes, batch_size, class_movies, class_dict, full_class_dict):\n",
    "    \"\"\"\n",
    "    :param batch_size: mini-batch size used during training\n",
    "    :param class_movies:  List containing per class a list of available movie names\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    no_shuffle = True\n",
    "\n",
    "    if not no_shuffle:\n",
    "        random.shuffle(classes)\n",
    "\n",
    "    # Fill the batch with frames from different movies\n",
    "    # If all movies contributes one frame and we extracted still fewer frames than batch_size, just start again\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        # Determine class of next element in batch from precreated list\n",
    "        rnd_cls = classes[i]\n",
    "\n",
    "        # Select a movie from this class, with a probability that is related to the amount of frames that are still available\n",
    "        rnd_movie = select_movie(rnd_cls, class_dict)\n",
    "\n",
    "        print('set rnd movie: ', rnd_movie)\n",
    "        # rnd_movie_name = class_movies[rnd_cls][rnd_movie]\n",
    "\n",
    "        # nr_frames = len(class_dict[rnd_cls][rnd_movie_name])\n",
    "        # if nr_frames == 0:\n",
    "        #     class_dict[rnd_cls][rnd_movie_name] = copy.deepcopy(full_class_dict[rnd_cls][rnd_movie_name])\n",
    "        #     #print(f'Fill again {rnd_movie_name} in class {rnd_cls}')\n",
    "        #     nr_frames = len(class_dict[rnd_cls][rnd_movie_name])\n",
    "\n",
    "        # rnd_frame = random.randrange(0,nr_frames)\n",
    "        # print('set rnd frame: ' , rnd_frame)\n",
    "\n",
    "        # frame = class_dict[rnd_cls][rnd_movie_name].pop(rnd_frame)\n",
    "\n",
    "        # hf = h5py.File(Path(rnd_movie_name)/(frame+\".hdf5\"), 'r')\n",
    "\n",
    "        # x.append(np.array(hf['image'], dtype=np.float32))\n",
    "        # y.append(np.array(hf[self.dict_key], dtype=np.float32))\n",
    "\n",
    "        # hf.close()\n",
    "\n",
    "    # # Stack all elements from the batch in an array\n",
    "    # x = np.stack(x)\n",
    "    # y = np.stack(y)\n",
    "    \n",
    "    # return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    0: {'movie1': 1, 'movie2': 2, 'movie1': 3, 'movie2': 4, 'movie1': 5, 'movie2': 6},\n",
    "    1: {'movie3': 7, 'movie4': 8, 'movie3': 9, 'movie4': 10, 'movie3': 11, 'movie4': 112},\n",
    "    2: {'movie5': 5, 'movie6': 6},\n",
    "    3: {'movie7': 7, 'movie8': 8}\n",
    "}\n",
    "class_movies = []\n",
    "batch_size = 8\n",
    "classes = [0,0,0,1,2,3]*int(np.ceil((batch_size/6)))\n",
    "full_class_dict = class_dict\n",
    "\n",
    "for cl in range(4):\n",
    "    class_movies.append(list(class_dict[cl].keys()))\n",
    "\n",
    "# while True:\n",
    "class_balanced_batch_generator(classes, batch_size, class_movies, class_dict, full_class_dict)\n",
    "# final_x, y_onehot = self.process_xy(x,y)\n",
    "# yield (final_x,y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
