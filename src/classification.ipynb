{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> GPU is available <---\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "\n",
    "from utils.loss import *\n",
    "from utils.metrics import *\n",
    "from utils.dataset import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "base_path = '/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning'\n",
    "if base_path not in sys.path:\n",
    "    sys.path.append(base_path)\n",
    "\n",
    "# import custom lib\n",
    "from src.utils.dataset import *\n",
    "from src.experiment import Experiment\n",
    "from models import resnet18 as r\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "if gpu:\n",
    "    tf.config.set_visible_devices([tf.config.list_physical_devices('GPU')[0],tf.config.list_physical_devices('CPU')[0]])\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "    print(\"---> GPU is available <---\")\n",
    "\n",
    "exps_path = '/Users/lorenzofederici/Univpm/Tesi/LUS-multitask-learning/config/params.json'\n",
    "\n",
    "with open(exps_path) as f:\n",
    "    configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(base_path, output_mode= (True,True))\n",
    "# TODO: chiedi a edo di smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> EXPERIMENT: exp_classification_ResNet_BS16_EP2_OPTSGD_LR0.01_AUGTrue__DT2211_1226 <<\n",
      "------------------------------------------------------------------------------------------\n",
      "230 videos (2154 frames) loaded from cached data.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> EXPERIMENT: exp_classification_ResNet_BS16_EP2_OPTSGD_LR0.01_AUGTrue__DT2211_1226 <<\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> EXPERIMENT: exp_classification_ResNet_BS16_EP2_OPTSGD_LR0.01_AUGTrue__DT2211_1226 <<\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> EXPERIMENT: exp_classification_ResNet_BS16_EP2_OPTSGD_LR0.01_AUGTrue__DT2211_1226 <<\n",
      "------------------------------------------------------------------------------------------\n",
      ">>Setting:  {'IMG_SHAPE': 224, 'N_CLASS': 4, 'SEED': 42}\n",
      ">>Experiment:  [{'backbone': 'ResNet', 'type': '18', 'task': 'classification', 'out_class': 4, 'batch_size': 16, 'epoch': 2, 'split_ratio': [0.6, 0.2, 0.2], 'optimizer': 'SGD', 'lr': 0.01, 'augmentation': True}, {'backbone': 'ResNet', 'type': '18', 'task': 'classification', 'out_class': 4, 'batch_size': 16, 'epoch': 2, 'split_ratio': [0.6, 0.2, 0.2], 'optimizer': 'SGD', 'lr': 0.01, 'augmentation': True, 'weights': 'imagenet', 'layer_to_freeze': 'enc_2'}, {'backbone': 'ResNet', 'type': '50', 'task': 'classification', 'out_class': 4, 'batch_size': 16, 'epoch': 2, 'split_ratio': [0.6, 0.2, 0.2], 'optimizer': 'SGD', 'lr': 0.01, 'augmentation': True}, {'backbone': 'ResNet', 'type': '50', 'task': 'classification', 'out_class': 4, 'batch_size': 16, 'epoch': 2, 'split_ratio': [0.6, 0.2, 0.2], 'optimizer': 'SGD', 'lr': 0.01, 'augmentation': True, 'weights': 'imagenet', 'layer_to_freeze': 'enc_2'}]\n",
      "\n",
      ">> SPLITTING:\n",
      ">>> Dataset Split: Train=1081(50%), Val=538(25%), Test=535(25%)\n",
      ">>> Train Class Weights: {0: 0.9583333333333334, 1: 1.004646840148699, 2: 0.7304054054054054, 3: 1.6890625}\n",
      ">>> Val Class Weights: {0: 0.682741116751269, 1: 1.2339449541284404, 2: 0.8053892215568862, 3: 2.0692307692307694}\n",
      ">>> Test Class Weights: {0: 0.6024774774774775, 1: 2.845744680851064, 2: 0.5765086206896551, 3: 3.9338235294117645}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:26:31.635252: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-22 12:26:31.635296: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-22 12:26:31.635302: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-22 12:26:31.635351: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-22 12:26:31.635378: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "configs_general = configs['SETTING']\n",
    "configs_exps    = configs['EXPS'][idx]\n",
    "\n",
    "for config in configs_exps:\n",
    "    experiment.build_experiment(configs_general, config)\n",
    "\n",
    "print('>>Setting: ', configs_general)\n",
    "print('>>Experiment: ', configs_exps)\n",
    "\n",
    "experiment.split_dataset()\n",
    "experiment.generate_split_charts('pierclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">> BUILDING MODEL:\n",
      "\tTask --> classification\n",
      "\tModel --> ResNet_50\n",
      "\tBatch size --> 16\n",
      "\tOptimizer --> SGD lr:0.01\n",
      "\tEpoch --> 2\n",
      "\tModel --> True\n",
      "\tDropout --> 0.0\n",
      "\tTrasfer learning Active from IMAGENET\n",
      "\tFreeze --> enc_2\n"
     ]
    }
   ],
   "source": [
    "K.clear_session\n",
    "model = experiment.build_model()\n",
    "model   = experiment.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\t\t   ~~~~~~ TRAINING ~~~~~\n",
      "------------------------------------------------------------\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 12:26:40.859692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 80s 1s/step - loss: 1.2095 - accuracy: 0.4681 - val_loss: 1.7927 - val_accuracy: 0.3086 - lr: 0.0100\n",
      "Epoch 2/2\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.7790 - accuracy: 0.6642 - val_loss: 1.8255 - val_accuracy: 0.2026 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "history = experiment.train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = experiment.evaluation_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.nn_train_graphs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from utils.loss import categorical_crossentropy\n",
    "from keras.optimizers.legacy import Adam, SGD\n",
    "from models.resnet18 import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definire la funzione del modello\n",
    "def build_model(hp):\n",
    "    model = resnet18((224, 224, 3), num_class=4)\n",
    "\n",
    "    hp_opt = Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    model.compile(\n",
    "        optimizer    = hp_opt,\n",
    "        loss         = categorical_crossentropy,\n",
    "        metrics      = 'accuracy')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  # Numero totale di prove di addestramento del modello\n",
    "    num_initial_points=2,  # Numero di punti iniziali per la ricerca casuale\n",
    "    directory=f'{base_path}/grid_result',  # Directory per salvare i risultati del tuner\n",
    "    project_name='my_project')  # Nome del progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_samples = len(experiment.train_subset_idxs)\n",
    "train_steps = train_samples // batch_size\n",
    "if train_samples % batch_size != 0:\n",
    "    train_steps += 1\n",
    "\n",
    "val_samples = len(experiment.val_subset_idxs)\n",
    "val_steps = val_samples // batch_size\n",
    "if val_samples % batch_size != 0:\n",
    "    val_steps += 1\n",
    "\n",
    "tuner.search(\n",
    "    experiment.train_ds,\n",
    "    epochs           = 10,\n",
    "    steps_per_epoch  = train_steps,\n",
    "    validation_data  = experiment.val_ds,\n",
    "    class_weight     = experiment.class_weight_dicts[0],\n",
    "    validation_steps = val_steps,\n",
    "    workers = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottenere il miglior modello\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Stampa delle migliori iperparametri\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
